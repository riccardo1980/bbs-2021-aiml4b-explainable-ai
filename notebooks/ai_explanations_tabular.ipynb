{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4qxwBA4RM9Lu"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"formazione-riccardo-zanella\" #@param {type: \"string\"}\n",
        "REGION = 'us-central1' #@param {type: \"string\"}\n",
        "BUCKET_NAME = \"bbs-2021-opml4b-explainability\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_NEAQwwH0e"
      },
      "source": [
        "## Build, train, and evaluate your model with Keras\n",
        "\n",
        "This section shows how to build, train, evaluate, and get local predictions from a model by using the Keras [Sequential API](https://www.tensorflow.org/guide/keras/sequential_model). The model will takes your 10 features as input and predict the trip duration in minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-22 14:33:49.308334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-10-22 14:33:49.308374: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_FILE = 'gs://'+BUCKET_NAME+'/data/train.csv'\n",
        "TEST_FILE = 'gs://'+BUCKET_NAME+'/data/test.csv'\n",
        "EXPORT_PATH = 'gs://' + BUCKET_NAME + '/explanations/mymodel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.io.gfile.GFile(TRAIN_FILE) as f:\n",
        "    train_data = pd.read_csv(f)\n",
        "\n",
        "with tf.io.gfile.GFile(TEST_FILE) as f:\n",
        "    test_data = pd.read_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def split_features_labels(dframe: pd.DataFrame, label_col: str = 'duration') -> Tuple[pd.DataFrame]:\n",
        "    labels = dframe[label_col]\n",
        "    features = dframe.drop(columns=[label_col])\n",
        "    return features, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, train_labels = split_features_labels(train_data)\n",
        "\n",
        "test_data, test_labels = split_features_labels(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3kQz8Q0DsBM7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-22 14:38:56.351778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2021-10-22 14:38:56.351815: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-10-22 14:38:56.351831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (INJ-NB-126): /proc/driver/nvidia/version does not exist\n",
            "2021-10-22 14:38:56.351988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Build your model\n",
        "model = tf.keras.Sequential(name=\"bike_predict\")\n",
        "model.add(tf.keras.layers.Dense(64, input_dim=len(train_data.iloc[0]), activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UvAcjSUcs_l7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"bike_predict\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,817\n",
            "Trainable params: 2,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Compile the model and see a summary\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer=optimizer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcOkuHPVwjiM"
      },
      "source": [
        "### Create an input data pipeline with tf.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZUu9wFklwmm6"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "epochs = 3\n",
        "\n",
        "input_train = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "output_train = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "input_train = input_train.batch(batch_size).repeat()\n",
        "output_train = output_train.batch(batch_size).repeat()\n",
        "train_dataset = tf.data.Dataset.zip((input_train, output_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l98aRzfPwo5e"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h1x_8CR0wtRs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "  69/2958 [..............................] - ETA: 4s - loss: 2.0662"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-22 14:39:58.528991: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2958/2958 [==============================] - 5s 1ms/step - loss: 0.7057\n",
            "Epoch 2/3\n",
            "2958/2958 [==============================] - 4s 1ms/step - loss: 0.3599\n",
            "Epoch 3/3\n",
            "2958/2958 [==============================] - 4s 1ms/step - loss: 0.3608\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faef1011e48>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This will take about a minute to run\n",
        "# To keep training time short, you're not using the full dataset\n",
        "train_size = len(train_data)\n",
        "model.fit(train_dataset, steps_per_epoch=train_size // batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPr0A8bjw0wm"
      },
      "source": [
        "### Evaluate the trained model locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3Elbvna4vU30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5917/5917 [==============================] - 4s 625us/step - loss: 0.3549\n",
            "0.3549324870109558\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bIh6uds2x2tr"
      },
      "outputs": [],
      "source": [
        "# Send test instances to model for prediction\n",
        "predict = model.predict(test_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aFjBh4DVx7QL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted duration: 18\n",
            "Actual duration: 22.0 \n",
            "\n",
            "Predicted duration: 27\n",
            "Actual duration: 31.0 \n",
            "\n",
            "Predicted duration: 27\n",
            "Actual duration: 23.0 \n",
            "\n",
            "Predicted duration: 17\n",
            "Actual duration: 14.0 \n",
            "\n",
            "Predicted duration: 12\n",
            "Actual duration: 9.0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview predictions on the first 5 examples from your test dataset\n",
        "for i, val in enumerate(predict):\n",
        "    print('Predicted duration: {}'.format(round(val[0])))\n",
        "    print('Actual duration: {} \\n'.format(test_labels.iloc[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gAO6-zv6osJ8"
      },
      "source": [
        "## Export the model as a TF 2.x SavedModel\n",
        "\n",
        "When using TensorFlow 2.x, you export the model as a `SavedModel` and load it into Cloud Storage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uV6l3_qF9iW7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-22 14:41:16.906603: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: gs://bbs-2021-opml4b-explainability/explanations/mymodel/assets\n",
            "gs://bbs-2021-opml4b-explainability/explanations/mymodel\n"
          ]
        }
      ],
      "source": [
        "model.save(EXPORT_PATH)\n",
        "print(EXPORT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f8elyM8KMNX"
      },
      "source": [
        "Use TensorFlow's `saved_model_cli` to inspect the model's SignatureDef. You'll use this information when you deploy your model to AI Explanations in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yFg5r-7s1BKr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-10-22 14:41:59.205271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-10-22 14:41:59.205311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1192, in main\n",
            "    args.func(args)\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 719, in show\n",
            "    _show_all(args.dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 307, in _show_all\n",
            "    _show_defined_functions(saved_model_dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 187, in _show_defined_functions\n",
            "    trackable_object = load.load(saved_model_dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 864, in load\n",
            "    result = load_internal(export_dir, tags, options)[\"root\"]\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 903, in load_internal\n",
            "    ckpt_options, options, filters)\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 162, in __init__\n",
            "    self._load_all()\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 259, in _load_all\n",
            "    self._load_nodes()\n",
            "  File \"/home/ricky/VSCODE/BBS/gcp_explainable_ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 448, in _load_nodes\n",
            "    slot_variable = optimizer_object.add_slot(\n",
            "AttributeError: '_UserObject' object has no attribute 'add_slot'\n"
          ]
        }
      ],
      "source": [
        "! saved_model_cli show --dir $EXPORT_PATH --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y270ZNinycoy"
      },
      "source": [
        "## Deploy the model to AI Explanations\n",
        "\n",
        "In order to deploy the model to Explanations, you need to generate an `explanations_metadata.json` file and upload this to the Cloud Storage bucket with your SavedModel. Then you'll deploy the model using `gcloud`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUdUVjjGbvQy"
      },
      "source": [
        "### Prepare explanation metadata\n",
        "\n",
        "In order to deploy this model to AI Explanations, you need to create an explanation_metadata.json file with information about your model inputs, outputs, and baseline. You can use the [Explainable AI SDK](https://pypi.org/project/explainable-ai-sdk/) to generate most of the fields. \n",
        "\n",
        "The value for `input_baselines` tells the explanations service what the baseline input should be for your model. Here you're using the median for all of your input features. That means the baseline prediction for this model will be the trip duration your model predicts for the median of each feature in your dataset. \n",
        "\n",
        "Since this model accepts a single numpy array with all numerical feature, you can optionally pass an `index_feature_mapping` list to AI Explanations to make the API response easier to parse. When you provide a list of feature names via this parameter, the service will return a key / value mapping of each feature with its corresponding attribution value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UolAW3lcVTGl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input tensor:  dense_input\n",
            "Model output tensor:  dense_2/BiasAdd:0\n"
          ]
        }
      ],
      "source": [
        "# Print the names of your tensors\n",
        "print('Model input tensor: ', model.input.name)\n",
        "print('Model output tensor: ', model.output.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qpZiW9Cq6IY4"
      },
      "outputs": [],
      "source": [
        "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
        "builder = SavedModelMetadataBuilder(export_path)\n",
        "builder.set_numeric_metadata(\n",
        "    model.input.name.split(':')[0],\n",
        "    input_baselines=[train_data.median().values.tolist()],\n",
        "    index_feature_mapping=train_data.columns.tolist()\n",
        ")\n",
        "builder.save_metadata(export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT3iG5pDdrHi"
      },
      "source": [
        "Since this is a regression model (predicting a numerical value), the baseline prediction will be the same for every example you send to the model. If this were instead a classification model, each class would have a different baseline prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6MKKy6Xb2MT"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "S2OaOycmb4o0"
      },
      "outputs": [],
      "source": [
        "MODEL = 'bike'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bwCxEr5b8BP"
      },
      "outputs": [],
      "source": [
        "# Create the model if it doesn't exist yet (you only need to run this once)\n",
        "! gcloud ai-platform models create $MODEL --enable-logging --region=$REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp4qfnZib-zQ"
      },
      "source": [
        "### Create the model version \n",
        "\n",
        "Creating the version will take ~5-10 minutes. Note that your first deploy could take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LQlcQFG_AB4o"
      },
      "outputs": [],
      "source": [
        "# Each time you create a version the name should be unique\n",
        "VERSION = 'v1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3l5t2o1t7dal"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.ai-platform.versions.create) Invalid choice: ''.\n",
            "This command is available in one or more alternate release tracks.  Try:\n",
            "  gcloud ai-platform versions create\n",
            "  gcloud alpha ai-platform versions create\n"
          ]
        }
      ],
      "source": [
        "# Create the version with gcloud\n",
        "explain_method = 'integrated-gradients'\n",
        "! gcloud beta ai-platform versions create $VERSION --region=$REGION \\\n",
        "--model $MODEL \\\n",
        "--origin $export_path \\\n",
        "--runtime-version 2.1 \\\n",
        "--framework TENSORFLOW \\\n",
        "--python-version 3.7 \\\n",
        "--machine-type n1-standard-4 \\\n",
        "--explanation-method $explain_method \\\n",
        "--num-integral-steps 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eWkkRFhEMbFa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "createTime: '2021-10-22T10:04:19Z'\n",
            "deploymentUri: gs://bbs-2021-opml4b-explainability/explanations/mymodel\n",
            "etag: aEdkYSb45jQ=\n",
            "explanationConfig:\n",
            "  integratedGradientsAttribution:\n",
            "    numIntegralSteps: 25\n",
            "framework: TENSORFLOW\n",
            "isDefault: true\n",
            "lastUseTime: '2021-10-22T10:19:16Z'\n",
            "machineType: n1-standard-4\n",
            "name: projects/formazione-riccardo-zanella/models/bike/versions/v1\n",
            "pythonVersion: '3.7'\n",
            "runtimeVersion: '2.1'\n",
            "state: READY\n"
          ]
        }
      ],
      "source": [
        "# Make sure the model deployed correctly. State should be `READY` in the following log\n",
        "! gcloud ai-platform versions describe $VERSION --region $REGION --model $MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JzevJps9IOcU"
      },
      "source": [
        "## Get predictions and explanations\n",
        "\n",
        "Now that your model is deployed, you can use the AI Platform Prediction API to get feature attributions. You'll pass it a single test example here and see which features were most important in the model's prediction. Here you'll use the [Explainable AI SDK](https://pypi.org/project/explainable-ai-sdk/) to get your prediction and explanation. You can also use `gcloud`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ-2ErWJDvcg"
      },
      "source": [
        "### Format your explanation request\n",
        "\n",
        "To make your AI Explanations request, you need to create a JSON object with your test data for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D_PR2BcHD40-"
      },
      "outputs": [],
      "source": [
        "# Format data for prediction to your model\n",
        "prediction_json = {model.input.name.split(':')[0]: test_data.iloc[0].values.tolist()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw7_f9QVD8Y_"
      },
      "source": [
        "### Send the explain request\n",
        "\n",
        "You can use the Explainable AI SDK to send explanation requests to your deployed model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9K1yt7z69iXY"
      },
      "outputs": [],
      "source": [
        "import explainable_ai_sdk\n",
        "remote_ig_model = explainable_ai_sdk.load_model_from_ai_platform(PROJECT_ID, MODEL, VERSION, region=REGION)\n",
        "ig_response = remote_ig_model.explain([prediction_json])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nKR8RelNnkK"
      },
      "source": [
        "### Understanding the explanations response\n",
        "\n",
        "First, let's look at the trip duration your model predicted and compare it to the actual value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "825KoNgHR-tv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted duration: 16.65 minutes\n",
            "Actual duration: 22.0 minutes\n"
          ]
        }
      ],
      "source": [
        "attr = ig_response[0].get_attribution()\n",
        "\n",
        "predicted = round(attr.example_score, 2)\n",
        "print('Predicted duration: ' + str(predicted) + ' minutes')\n",
        "print('Actual duration: ' + str(test_labels.iloc[0]) + ' minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmObtmXIONDp"
      },
      "source": [
        "Next let's look at the feature attributions for this particular example. Positive attribution values mean a particular feature pushed your model prediction up by that amount, and vice versa for negative attribution values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6HKvAImeM_qi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Index 0\n",
            "Example Score: 16.6543\n",
            "Baseline Score: 13.0743\n",
            "Approximation Error: 0.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ig_response[0].visualize_attributions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZiM7kywQy6j"
      },
      "source": [
        "## Check your explanations and baselines\n",
        "\n",
        "To better make sense of the feature attributions you're getting, you should compare them with your model's baseline. In most cases, the sum of your attribution values + the baseline should be very close to your model's predicted value for each input. Also note that for regression models, the `baseline_score` returned from AI Explanations will be the same for each example sent to your model. For classification models, each class will have its own baseline.\n",
        "\n",
        "In this section you'll send 10 test examples to your model for prediction in order to compare the feature attributions with the baseline. Then you'll run each test example's attributions through two sanity checks in the `sanity_check_explanations` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CSf6psVDSDrN"
      },
      "outputs": [],
      "source": [
        "# Prepare 10 test examples to your model for prediction\n",
        "pred_batch = []\n",
        "for i in range(10):\n",
        "    pred_batch.append({model.input.name.split(':')[0]: test_data.iloc[i].values.tolist()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M-lqktTI9iXj"
      },
      "outputs": [],
      "source": [
        "test_response = remote_ig_model.explain(pred_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEevMCrMNjxm"
      },
      "source": [
        "In the function below you perform two sanity checks for models using Integrated Gradient (IG) explanations and one sanity check for models using Sampled Shapley."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "B_WQXkE6RLe4"
      },
      "outputs": [],
      "source": [
        "def sanity_check_explanations(example, mean_tgt_value=None, variance_tgt_value=None):\n",
        "    passed_test = 0\n",
        "    total_test = 1\n",
        "    # `attributions` is a dict where keys are the feature names\n",
        "    # and values are the feature attributions for each feature\n",
        "    attr = example.get_attribution()\n",
        "    baseline_score = attr.baseline_score\n",
        "    # sum_with_baseline = np.sum(attribution_vals) + baseline_score\n",
        "    predicted_val = attr.example_score\n",
        "\n",
        "    # Sanity check 1\n",
        "    # The prediction at the input is equal to that at the baseline.\n",
        "    #  Please use a different baseline. Some suggestions are: random input, training\n",
        "    #  set mean.\n",
        "    if abs(predicted_val - baseline_score) <= 0.05:\n",
        "        print('Warning: example score and baseline score are too close.')\n",
        "        print('You might not get attributions.')\n",
        "    else:\n",
        "        passed_test += 1\n",
        "\n",
        "    # Sanity check 2 (only for models using Integrated Gradient explanations)\n",
        "    # Ideally, the sum of the integrated gradients must be equal to the difference\n",
        "    # in the prediction probability at the input and baseline. Any discrepency in\n",
        "    # these two values is due to the errors in approximating the integral.\n",
        "    if explain_method == 'integrated-gradients':\n",
        "        total_test += 1\n",
        "        want_integral = predicted_val - baseline_score\n",
        "        got_integral = sum(attr.post_processed_attributions.values())\n",
        "        if abs(want_integral - got_integral) / abs(want_integral) > 0.05:\n",
        "            print('Warning: Integral approximation error exceeds 5%.')\n",
        "            print('Please try increasing the number of integrated gradient steps.')\n",
        "        else:\n",
        "            passed_test += 1\n",
        "\n",
        "    print(passed_test, ' out of ', total_test, ' sanity checks passed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dkpK830AtRkJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n",
            "2  out of  2  sanity checks passed.\n"
          ]
        }
      ],
      "source": [
        "for response in test_response:\n",
        "    sanity_check_explanations(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ur65baOmnn"
      },
      "source": [
        "## Understanding AI Explanations with the What-If Tool\n",
        "\n",
        "In this section you'll use the [What-If Tool](https://pair-code.github.io/what-if-tool/) to better understand how your model is making predictions. See the cell below the What-if Tool for visualization ideas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFO6s8ZsvKT_"
      },
      "source": [
        "The What-If-Tool expects data with keys for each feature name, but your model expects a flat list. The functions below convert data to the format required by the What-If Tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-yajpXi4Oyc3"
      },
      "outputs": [],
      "source": [
        "# This is the number of data points you'll send to the What-if Tool\n",
        "WHAT_IF_TOOL_SIZE = 500\n",
        "\n",
        "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
        "\n",
        "\n",
        "def create_list(ex_dict):\n",
        "    new_list = []\n",
        "    for i in feature_names:\n",
        "        new_list.append(ex_dict[i])\n",
        "    return new_list\n",
        "\n",
        "\n",
        "def example_dict_to_input(example_dict):\n",
        "    return {'dense_input': create_list(example_dict)}\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "wit_data = test_data.iloc[:WHAT_IF_TOOL_SIZE].copy()\n",
        "wit_data['duration'] = test_labels[:WHAT_IF_TOOL_SIZE]\n",
        "wit_data_dict = wit_data.to_dict(orient='records', into=OrderedDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3I2bEUe7Pr2Y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c495a6e4e1b34a80800bafbd36b0681e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "WitWidget(config={'model_type': 'regression', 'label_vocab': [], 'uses_json_input': True, 'inference_address':…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "config_builder = WitConfigBuilder(\n",
        "    wit_data_dict\n",
        ").set_ai_platform_model(\n",
        "    PROJECT_ID,\n",
        "    MODEL,\n",
        "    VERSION,\n",
        "    adjust_example=example_dict_to_input\n",
        ").set_target_feature('duration').set_model_type('regression')\n",
        "\n",
        "WitWidget(config_builder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmNoC6FxOAt"
      },
      "source": [
        "### What-If Tool visualization ideas\n",
        "\n",
        "On the x-axis, you'll see the predicted trip duration for the test inputs you passed to the What-If Tool. Each circle represents one of your test examples. If you click on a circle, you'll be able to see the feature values for that example along with the attribution values for each feature. \n",
        "\n",
        "* You can edit individual feature values and re-run prediction directly within the What-If Tool. Try changing `distance`, click **Run inference** and see how that affects the model's prediction\n",
        "* You can sort features for an individual example by their attribution value, try changing the sort from the attributions dropdown\n",
        "* The What-If Tool also lets you create custom visualizations. You can do this by changing the values in the dropdown menus above the scatter plot visualization. For example, you can sort data points by inference error, or by their similarity to a single datapoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3F2g4OjbJ3gZ"
      },
      "source": [
        "If your Cloud Storage bucket doesn't contain any other objects and you would like to delete it, run `gsutil rm -r gs://$BUCKET_NAME`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "K0UXLWaBJnrY"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "To learn more about AI Explanations or the What-if Tool, check out the resources here.\n",
        "\n",
        "* [AI Explanations documentation](cloud.google.com/ml-engine/docs/ai-explanations)\n",
        "* [Documentation for using the What-if Tool with Cloud AI Platform models ](https://cloud.google.com/ml-engine/docs/using-what-if-tool) \n",
        "* [What-If Tool documentation and demos](https://pair-code.github.io/what-if-tool/)\n",
        "* [Integrated gradients paper](https://arxiv.org/abs/1703.01365)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai-explanations-tabular.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "564b7b694546c621da9d6821e01f599815a761b7862c6a664e5ab5e1f8729b63"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
