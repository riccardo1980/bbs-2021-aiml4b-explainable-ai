{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4qxwBA4RM9Lu"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"formazione-riccardo-zanella\"\n",
        "REGION = 'us-central1'\n",
        "BUCKET_NAME = \"bbs-2021-opml4b-explainability\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_FILE = 'gs://'+BUCKET_NAME+'/data/tabular_data/train.csv'\n",
        "\n",
        "EXPORT_PATH = 'gs://' + BUCKET_NAME + '/mdl/tabular_data/tabular_data_20211117_172620/model/'\n",
        "\n",
        "MODEL = 'bike'\n",
        "VERSION = 'v1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-17 17:41:40.157364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-11-17 17:41:40.157406: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gAO6-zv6osJ8"
      },
      "source": [
        "# Inspect model's signature\n",
        "\n",
        "When using TensorFlow 2.x, you export the model as a `SavedModel` and load it into Cloud Storage. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using command line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f8elyM8KMNX"
      },
      "source": [
        "Use TensorFlow's `saved_model_cli` to inspect the model's SignatureDef. You'll use this information when you deploy your model to AI Explanations in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yFg5r-7s1BKr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-17 17:41:41.780912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-11-17 17:41:41.780955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 6)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1192, in main\n",
            "    args.func(args)\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 719, in show\n",
            "    _show_all(args.dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 307, in _show_all\n",
            "    _show_defined_functions(saved_model_dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 187, in _show_defined_functions\n",
            "    trackable_object = load.load(saved_model_dir)\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 864, in load\n",
            "    result = load_internal(export_dir, tags, options)[\"root\"]\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 903, in load_internal\n",
            "    ckpt_options, options, filters)\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 162, in __init__\n",
            "    self._load_all()\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 259, in _load_all\n",
            "    self._load_nodes()\n",
            "  File \"/home/ricky/VSCODE/BBS/bbs-2021-aiml4b-explainable-ai/.venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 448, in _load_nodes\n",
            "    slot_variable = optimizer_object.add_slot(\n",
            "AttributeError: '_UserObject' object has no attribute 'add_slot'\n"
          ]
        }
      ],
      "source": [
        "! saved_model_cli show --dir $EXPORT_PATH --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using TensorFlow API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-17 17:41:51.069387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2021-11-17 17:41:51.069481: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-11-17 17:41:51.069517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (INJ-NB-126): /proc/driver/nvidia/version does not exist\n",
            "2021-11-17 17:41:51.069946: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input tensor:  dense_input\n",
            "Model output tensor:  dense_2/BiasAdd:0\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(EXPORT_PATH)\n",
        "# Print the names of your tensors\n",
        "print('Model input tensor: ', model.input.name)\n",
        "print('Model output tensor: ', model.output.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y270ZNinycoy"
      },
      "source": [
        "# Deploy the model to AI Explanations\n",
        "\n",
        "In order to deploy the model to Explanations, you need to generate an `explanations_metadata.json` file and upload this to the Cloud Storage bucket with your SavedModel. Then you'll deploy the model using `gcloud`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUdUVjjGbvQy"
      },
      "source": [
        "## Prepare explanation metadata\n",
        "\n",
        "In order to deploy this model to AI Explanations, you need to create an explanation_metadata.json file with information about your model inputs, outputs, and baseline. You can use the [Explainable AI SDK](https://pypi.org/project/explainable-ai-sdk/) to generate most of the fields. \n",
        "\n",
        "The value for `input_baselines` tells the explanations service what the baseline input should be for your model. Here you're using the median for all of your input features. That means the baseline prediction for this model will be the trip duration your model predicts for the median of each feature in your dataset. \n",
        "\n",
        "Since this model accepts a single numpy array with all numerical feature, you can optionally pass an `index_feature_mapping` list to AI Explanations to make the API response easier to parse. When you provide a list of feature names via this parameter, the service will return a key / value mapping of each feature with its corresponding attribution value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.io.gfile.GFile(TRAIN_FILE) as f:\n",
        "    train_data = pd.read_csv(f)\n",
        "\n",
        "features = train_data.drop(columns=['duration'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "FEATURE_NAMES = features.columns.tolist()\n",
        "INPUT_BASELINES = features.median().to_list() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start_hr: 14.0\n",
            "weekday: 4.0\n",
            "euclidean: 1797.8503302971844\n",
            "temp: 55.1\n",
            "dew_point: 46.2\n",
            "max_temp: 62.2\n"
          ]
        }
      ],
      "source": [
        "for f,v in zip (FEATURE_NAMES, INPUT_BASELINES):\n",
        "    print('{}: {}'.format(f,v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qpZiW9Cq6IY4"
      },
      "outputs": [],
      "source": [
        "builder = SavedModelMetadataBuilder(EXPORT_PATH)\n",
        "\n",
        "builder.set_numeric_metadata(\n",
        "    model.input.name.split(':')[0],\n",
        "    input_baselines=INPUT_BASELINES,\n",
        "    index_feature_mapping=FEATURE_NAMES\n",
        ")\n",
        "\n",
        "builder.save_metadata(EXPORT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT3iG5pDdrHi"
      },
      "source": [
        "Since this is a regression model (predicting a numerical value), the baseline prediction will be the same for every example you send to the model. If this were instead a classification model, each class would have a different baseline prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6MKKy6Xb2MT"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0bwCxEr5b8BP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in projects [formazione-riccardo-zanella] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - description: A model with the same name already exists.\n",
            "    field: model.name\n"
          ]
        }
      ],
      "source": [
        "# Create the model if it doesn't exist yet (you only need to run this once)\n",
        "! gcloud ai-platform models create $MODEL --enable-logging --region=$REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp4qfnZib-zQ"
      },
      "source": [
        "### Create the model version \n",
        "\n",
        "Creating the version will take ~5-10 minutes. Note that your first deploy could take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3l5t2o1t7dal"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "Explanations reflect patterns in your model, but don't necessarily reveal fundamental relationships about your data population. See https://cloud.google.com/ml-engine/docs/ai-explanations/limitations for more information.\n",
            "Creating version (this might take a few minutes)......done.\n"
          ]
        }
      ],
      "source": [
        "# Create the version with gcloud\n",
        "explain_method = 'sampled-shapley'\n",
        "! gcloud beta ai-platform versions create $VERSION --region=$REGION \\\n",
        "--model $MODEL \\\n",
        "--origin $EXPORT_PATH \\\n",
        "--runtime-version 2.1 \\\n",
        "--framework TENSORFLOW \\\n",
        "--python-version 3.7 \\\n",
        "--machine-type n1-standard-4 \\\n",
        "--explanation-method $explain_method \\\n",
        "--num-integral-steps 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eWkkRFhEMbFa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "createTime: '2021-11-17T16:42:41Z'\n",
            "deploymentUri: gs://bbs-2021-opml4b-explainability/mdl/tabular_data/tabular_data_20211117_172620/model/\n",
            "etag: h-pu1mNPSWc=\n",
            "explanationConfig:\n",
            "  sampledShapleyAttribution:\n",
            "    numPaths: 50\n",
            "framework: TENSORFLOW\n",
            "isDefault: true\n",
            "machineType: n1-standard-4\n",
            "name: projects/formazione-riccardo-zanella/models/bike/versions/v1\n",
            "pythonVersion: '3.7'\n",
            "runtimeVersion: '2.1'\n",
            "state: READY\n"
          ]
        }
      ],
      "source": [
        "# Make sure the model deployed correctly. State should be `READY` in the following log\n",
        "! gcloud ai-platform versions describe $VERSION --region $REGION --model $MODEL"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai-explanations-tabular.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "a0084c784bc1853f1457fd28c44f23a4ba2b730805a7884d767b56d58b716959"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
